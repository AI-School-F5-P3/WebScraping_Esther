# WebScraping_Esther
# ğŸŒ Proyecto Web Scraping

## ğŸ“ Briefing: Proyecto de Web Scraping

### ğŸ“‹ Planteamiento
La empresa **XYZ Corp** busca una frase que refleje sus valores y misiÃ³n. Para ello, desarrollaremos un programa en **Python** que realizarÃ¡ **web scraping** para extraer frases de la web [https://quotes.toscrape.com/](https://quotes.toscrape.com/), junto con los autores, tags asociados y la pÃ¡gina "about" con informaciÃ³n de los autores. Los datos extraÃ­dos serÃ¡n formateados y almacenados adecuadamente.

### ğŸ¯ Objetivos del Proyecto
1. **Acceder a la web**: Obtener frases con informaciÃ³n relacionada.
2. **Extraer informaciÃ³n**: Utilizar tÃ©cnicas de web scraping en Python.
3. **Formatear los datos**: Asegurarse de que los datos estÃ©n organizados.
4. **Almacenar los datos**: Guardar la informaciÃ³n extraÃ­da en una base de datos.


### ğŸ› ï¸ TecnologÃ­as Ãºtilizadas
- **Git/GitHub**
- **Python** (bibliotecas: BeautifulSoup,Requests)
- **Herramientas de gestiÃ³n de proyectos** (Trello)

### ğŸ“Š Niveles de Entrega

#### Nivel Esencial
- Script que accede a la web, extrae frases e imprime en consola.
- Limpieza bÃ¡sica de datos extraÃ­dos.
- DocumentaciÃ³n bÃ¡sica del cÃ³digo y README en GitHub.

### Nivel Medio
- Almacenamiento de los datos extraÃ­dos en una base de datos.
- ImplementaciÃ³n de un sistema de logs para la trazabilidad del cÃ³digo.

## ğŸ“‚ Estructura del Proyecto

```plaintext
Proyecto Web Scraping/
â”œâ”€â”€ venv/
â”œâ”€â”€ WebScraping_Esther/
â”‚   â”œâ”€â”€ log/
â”‚   â”‚   â””â”€â”€ scraping.log
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ test_main.py
â”œâ”€â”€ README.md
â””â”€â”€ .env

ğŸŒŸ DescripciÃ³n Adicional
CreaciÃ³n del Entorno Virtual (venv)
Para crear un entorno virtual en Python y activarlo, se utilizaron los siguientes comandos:

bash

# Crear el entorno virtual
python -m venv venv

# Activar el entorno virtual (Windows)
venv\Scripts\activate

# Instalar librerÃ­as desde requirements.txt
pip install -r requirements.txt

# CreaciÃ³n del Archivo .env
El archivo .env se utiliza para almacenar informaciÃ³n sensible como las credenciales de la base de datos. Para crear el archivo .env, sigue estos pasos:

Crea un archivo llamado .env en la raÃ­z del proyecto.
AÃ±ade las siguientes variables con los valores correspondientes:
USER=tu_usuario
PASSWORD=tu_contraseÃ±a
HOST=tu_host
PORT=tu_puerto
DATABASE=tu_base_de_datos

# ConexiÃ³n a PostgreSQL con SQLAlchemy y os
Para conectar a la base de datos PostgreSQL, se utilizan las librerÃ­as sqlalchemy y os. La conexiÃ³n se define de la siguiente manera en el archivo main.py:

import os
from sqlalchemy import create_engine
from dotenv import load_dotenv

load_dotenv()

USER = os.getenv('USER')
PWD = os.getenv('PASSWORD')
HOST = os.getenv('HOST')
PORT = os.getenv('PORT')
DATABASE = os.getenv('DATABASE')

connection_string = f'postgresql://{USER}:{PWD}@{HOST}:{PORT}/{DATABASE}'
engine = create_engine(connection_string)

# ConfiguraciÃ³n de logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    filename='WebScraping_Esther/log/scraping.log',
                    filemode='a',
                    encoding='utf-8')


Resumen del CÃ³digo de Web Scraping
El cÃ³digo realiza las siguientes acciones:

ConexiÃ³n a la Base de Datos: Utiliza las credenciales almacenadas en el archivo .env para conectarse a PostgreSQL.
ExtracciÃ³n de Datos: Utiliza la librerÃ­a requests para acceder a la web y BeautifulSoup para extraer y parsear las frases, autores, tags, y la informaciÃ³n adicional de los autores.
Almacenamiento de Datos: Los datos extraÃ­dos se almacenan en un DataFrame de pandas y luego se envÃ­an a una tabla en la base de datos PostgreSQL utilizando SQLAlchemy.
Logging: Se utiliza la librerÃ­a logging para registrar las actividades y errores durante la ejecuciÃ³n del script.











